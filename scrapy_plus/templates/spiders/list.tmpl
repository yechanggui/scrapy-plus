# -*- coding: utf-8 -*-
# @Author: Vincent <yecg@ruyi.ai>
import scrapy
from urllib import urlencode
from scrapy.selector import Selector
from scrapy_redis.spiders import RedisSpider
from $project_name.items import ${ProjectName}Item
from tool.data import clean
# from scrapy_redis.spiders import RedisSpider

_META_VERSION = 'v1.0'
class $classname(scrapy.Spider):
    name = '$name'
    meta_version = _META_VERSION
    result_dir = './result'
    custom_settings = {
        'DOWNLOAD_DELAY': 0,
        'ITEM_PIPELINES': {
            # '$project_name.pipelines.${ProjectName}Pipeline': 300,
            # '$project_name.pipelines.MongoDBPipleline': 301
        },
        'DOWNLOADER_MIDDLEWARES': {
            # 'scrapy.downloadermiddlewares.retry.RetryMiddleware': 80,
            # '$project_name.middlewares.ProxyPoolMiddleware': 90,
            # 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware': 100,
        },
        'AUTOTHROTTLE_ENABLED': False,
    }
    def start_requests(self):
        for i in range(1):
            yield scrapy.Request(url=''.format(i+1),callback=self.parse_list)

    def parse_list(self, response):
        selector = Selector(response)
        selector.xpath('')
        yield scrapy.Request(url='',callback=self.parse_detail)


    def parse_detail(self, response):
        selector = Selector(response)
        item = ${ProjectName}Item()
        item['url'] = response.request.url
        selector.xpath('')
        yield item
